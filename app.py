import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import classification_report
from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler

# Configuration Streamlit
st.set_page_config(
    page_title="Alzheimer Disease Prediction",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Ajouter du CSS pour le style
st.markdown("""
    <style>
        .sidebar .sidebar-content {
            padding: 0;
        }
        .btn {
            width: 100%;
            padding: 15px;
            font-size: 16px;
            text-align: center;
            color: white;
            background-color: #4CAF50;
            border: none;
            margin-bottom: 10px;
            cursor: pointer;
        }
        .btn:hover {
            background-color: #45a049;
        }
        .block-container {
            padding: 0 2rem;
        }
    </style>
""", unsafe_allow_html=True)

# Charger le dataset automatiquement
try:
    df = pd.read_csv("alzheimers_disease_data3.csv")
except FileNotFoundError:
    st.error("Le fichier 'alzheimers_disease_data3.csv' est introuvable dans le dossier actuel. Veuillez v√©rifier.")

# Gestion des pages avec st.session_state
if "current_page" not in st.session_state:
    st.session_state["current_page"] = "Introduction"

# Gestion des pages avec des boutons
if st.sidebar.button("üîç Introduction", key="btn_intro"):
    st.session_state["current_page"] = "Introduction"
if st.sidebar.button("üìÇ Aper√ßu des Donn√©es", key="btn_data"):
    st.session_state["current_page"] = "Aper√ßu des Donn√©es"
if st.sidebar.button("üîß Pr√©traitement", key="btn_preprocess"):
    st.session_state["current_page"] = "Pr√©traitement"
if st.sidebar.button("ü§ñ Mod√©lisation", key="btn_model"):
    st.session_state["current_page"] = "Mod√©lisation"
if st.sidebar.button("üìä Visualisations", key="btn_visualize"):
    st.session_state["current_page"] = "Visualisations"

# Utiliser st.session_state pour afficher la bonne page
current_page = st.session_state["current_page"]

# Section : Introduction
if current_page == "Introduction":
    st.title("üîç Alzheimer Disease Prediction")
    st.markdown(
        """
        üß†Bienvenue dans cette application de pr√©diction pour la maladie d'Alzheimer. 
        Vous pourrez : 
        
        Un syst√®me interactif de visualisation et de pr√©diction des donn√©es li√© √† la maladie d'Alzheimer.
        - Charger un dataset (pr√©-charg√© automatiquement)
        - Pr√©traiter les donn√©es
        - Entra√Æner diff√©rents mod√®les de machine learning
        - Visualiser les r√©sultats.
        """
    )
# Section : Aper√ßu des Donn√©es
elif current_page == "Aper√ßu des Donn√©es":
    st.title("üìÇ Aper√ßu des Donn√©es")
    if df is not None:
        st.write("Aper√ßu des donn√©es :")
        st.write(df.shape)
        st.dataframe(df)

        st.write("Statistiques descriptives :")
        st.write(df.describe())

        st.write("Nombre des lignes duppliqu√©es :", sum(df.duplicated()))

        categorical_vars = df.select_dtypes(include=['object']).columns
        numeric_vars = df.select_dtypes(include=['number']).columns

        # Afficher la categorie de variables
        st.write("Variables cat√©gorielles :", categorical_vars)
        st.write("Variables num√©riques :", numeric_vars)
    else:
        st.warning("Le dataset n'est pas charg√©.")

# Section : Pr√©traitement des Donn√©es
elif current_page == "Pr√©traitement":
    st.title("üîß Pr√©traitement des Donn√©es")
    if df is not None:
        # Suppression des colonnes inutiles
        if "PatientID" in df.columns:
            df = df.drop(columns=["PatientID"])
        if "DoctorInCharge" in df.columns:
            df = df.drop(columns=["DoctorInCharge"])

        # Encodage des variables cat√©gorielles
        categorical_columns = df.select_dtypes(include="object").columns
        label_encoder = LabelEncoder()
        for col in categorical_columns:
            df[col] = label_encoder.fit_transform(df[col])

        # Normalisation des colonnes num√©riques
        numeric_columns = df.select_dtypes(include=["float64", "int64"]).columns
        scaler = MinMaxScaler()
        df[numeric_columns] = scaler.fit_transform(df[numeric_columns])

        st.write("Donn√©es apr√®s pr√©traitement :")
        st.dataframe(df.head())
    else:
        st.warning("Le dataset n'est pas charg√©.")

# Section : Mod√©lisation
elif current_page == "Mod√©lisation":
    st.title("ü§ñ Mod√©lisation")
    if df is not None:

        categorical_vars = df.select_dtypes(include=['object']).columns
        numeric_vars = df.select_dtypes(include=['number']).columns

        labelencoder_X = LabelEncoder()
        for col in categorical_vars:
            df[col] = labelencoder_X.fit_transform(df[col])

        columns = ['Age', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'SleepQuality', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment', 'ADL']

        #normalize the columns
        min_max_scaler = MinMaxScaler()
        df[columns] = min_max_scaler.fit_transform(df[columns])

        #standardize the columns
        standard_scaler = StandardScaler()
        df[columns] = standard_scaler.fit_transform(df[columns])


        # S√©paration des donn√©es
        X = df.drop(columns=["Diagnosis"])
        y = df["Diagnosis"]
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # Param√®tres des mod√®les
        param_grids = {
            'Decision Tree': {'max_depth': [3, 5, 7, 12, None]},
            'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 12, None]},
            'K-Nearest Neighbors': {'n_neighbors': [3, 5, 7]},
            'Logistic Regression': {'C': [0.1, 1, 10]},
            'Support Vector Machine': {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 'scale', 'auto']},
            'XGBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 7]},
            'CatBoost': {'iterations': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1]}
        }

        # Mod√®les disponibles
        models = {
            "Decision Tree": DecisionTreeClassifier(),
            "Random Forest": RandomForestClassifier(),
            "K-Nearest Neighbors": KNeighborsClassifier(),
            "Logistic Regression": LogisticRegression(),
            "Support Vector Machine": SVC(),
            "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss"),
            "CatBoost": CatBoostClassifier(verbose=0),
        }

        selected_model = st.selectbox("Choisissez un mod√®le", list(models.keys()))

        model = models[selected_model]
        grid_search = GridSearchCV(model, param_grids[selected_model], cv=5, scoring='f1')
        grid_search.fit(X_train, y_train)
        best_model = grid_search.best_estimator_

        # Afficher les r√©sultats de la classification
        y_pred = best_model.predict(X_test)
        st.write(f"Classification Report pour {selected_model}:")
        st.text(classification_report(y_test, y_pred))

        st.write("Meilleurs param√®tres trouv√©s:", grid_search.best_params_)
    else:
        st.warning("Le dataset n'est pas charg√©.")

# Section : Visualisations
elif current_page == "Visualisations":
    st.title("üìä Visualisations")
    if df is not None:
        # Distribution de la variable cible
        st.subheader("Distribution de la variable cible")
        fig, ax = plt.subplots()
        df["Diagnosis"].value_counts().plot.pie(autopct="%1.1f%%", ax=ax)
        st.pyplot(fig)

        # Matrice de corr√©lation
        numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()
        st.subheader("Matrice de corr√©lation")
        fig, ax = plt.subplots(figsize=(30, 10))
        sns.heatmap(df[numerical_features].corr(), annot=True, cmap="coolwarm", ax=ax)
        st.pyplot(fig)
    else:
        st.warning("Le dataset n'est pas charg√©.")
